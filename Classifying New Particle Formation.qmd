---
title: "Classifying New Particle Formation"
execute: 
  echo: false
format:
  pdf
---
```{python}
#Tähän ulkopuoliset importit
import matplotlib.pyplot as plt
import pandas as pd
```

```{python}
#Tähän Eliaksen importit
from subset_selection import cv_results, RFE_df
```

```{python}
#Tähän Joken importit
import pca
```

Group: John 117

Members: Elias Toukolehto and Joacim Sarén

# Preprocessing

We decided to start by trying feature selection and dimensionality reduction via principal component analysis with a few different machine learning models.

## Principal component analysis

First we looked at cumulative proportion of variance explained by the principal components. We used l2 normalization. We looked at the behaviour of PCA and all the models at upto 100 components, but nothing interesting happened with any of them beyond about 40 components, so the charts here focus on 40 or less components. Accuracy is measured as the average accuracy using 10-fold cross validation.

```{python}
plt.plot(range(1, 41), pca.cum_pve)
plt.hlines(1, 0, 40, 'red', 'dotted')
plt.show()
```

Then we looked at the accuracy of logistic regression, decision tree and gaussian naive Bayes classifiers with different numbers of principal components for binary and multiclass classification.

```{python}
plt.plot(range(1, 41), pca.nbscore2, color='red', label='Naive Bayes')
plt.plot(range(1, 41), pca.treescore2, color='blue', label='Decision tree')
plt.plot(range(1, 41), pca.lrscore2, color='green', label='logistic regression')
plt.legend()
plt.title('Binary classification accuracy')
plt.show()

plt.plot(range(1, 41), pca.nbscore4, color='red', label='Naive Bayes')
plt.plot(range(1, 41), pca.treescore4, color='blue', label='Decision tree')
plt.plot(range(1, 41), pca.lrscore4, color='green', label='logistic regression')
plt.legend()
plt.title('Multiclass classification accuracy')
plt.show()
```

The gaussian Naive Bayes classifier with 9 predictors is clearly the best oferall performer out of the tested models.

## Feature selection

Another preprocessing method is feature selection, for which we have used Recursive Feature elimination using 5-fold cross validation, which is a form of backward selection.
With RFE we get the following results for binary classification

```{python}
print(RFE_df)
```

on this table we can compare the improvements RFE provides, able to increase binary classification accuracy by couple percent compared to including all features.

```{python}
LR1_results = cv_results[0].iloc[:40]
LR2_results = cv_results[1].iloc[:40]

plt.plot(LR1_results["n_features"], LR1_results["mean_test_score"], color='red', label='LR (Lasso)')
plt.plot(LR2_results["n_features"], LR2_results["mean_test_score"], color='blue', label='LR (Ridge)')

plt.legend()
plt.title('RFE binary classification accuracy')
plt.show()

```

We can see that increasing features results in better accuracy, usually having the best accuracy at 10-20 features.
We currently only have linear regression with L1 (lasso) and L2 (ridge) penalties. After comparing different models, we will probably use some combination of PCA and Feature selection in our final model

# Feature analysis

Analyzing coefficients allowed us to rank some features by usefulness. The ones for the plot below were defined by performance with logistic regression using 5-fold cross validation.

```{python}
df = pd.read_csv('train.csv')

df = df.drop(columns=['id', 'date', 'partlybad'])

train_x = df.drop(columns=['class4'])
train_x = (train_x-train_x.mean())/train_x.std()

train_y = df['class4']

df = train_x.copy()
df['class4'] = train_y

best5 = ['CS.mean', 'SWS.std', 'RHIRGA672.mean', 'PAR.mean', 'Glob.mean']
worst5 = ['NOx672.mean', 'CO2504.std','NO168.std', 'NO336.mean', 'CO2504.std']

fig, axs = plt.subplots(2,5)

nonevent_df = df[df['class4'] == 'nonevent']
event_df = df[df['class4'] != 'nonevent']


for i in range(0,10):

  if i < 5:
    axs[0,i].set_title(best5[i])
    axs[0,i].boxplot([nonevent_df[best5[i]], event_df[best5[i]]], tick_labels=['non', 'event'], sym='_')
  else:
    axs[1,i-5].set_title(worst5[i-5])
    axs[1,i-5].boxplot([nonevent_df[worst5[i-5]], event_df[worst5[i-5]]], tick_labels=['non', 'event'], sym='_')
  

plt.tight_layout()
plt.show()
```

Here are boxplots of some of the most useful (top row), and least useful (bottom row) features for binary classification in the dataset. For the reliable features we can see that the quartaile ranges don't have much overlap, as for the unreliable features there is a lot of overlap between classes. CS.mean is an oulkier, where models find it very useful even though it has surprisingly similar boxplots between classes.